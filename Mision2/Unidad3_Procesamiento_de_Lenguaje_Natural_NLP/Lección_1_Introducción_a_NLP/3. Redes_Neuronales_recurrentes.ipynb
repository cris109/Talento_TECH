{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvmdCF92WqfLqp6VxwWsAR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Preprocesamiento de datos\n","...El mismo de la actividad anterior"],"metadata":{"id":"u7637VhBrZE9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7Hy9VIaP2o-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import keras"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/sample_data/IMDB Dataset.csv\")\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpbzaQPKShX6","executionInfo":{"status":"ok","timestamp":1715388309901,"user_tz":300,"elapsed":1093,"user":{"displayName":"Cristina Ortega","userId":"10739822531022913396"}},"outputId":"e2174f49-2d8b-4b1c-a3d0-f97885636a31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"]}]},{"cell_type":"code","source":["review = []\n","sentences = list(df['review'])\n","for sen in sentences:\n","  review.append(sen)"],"metadata":{"id":"ihAH8Z_1Y7h7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = df['sentiment']\n","labels = np.array(list(map(lambda x: 1 if x ==\"positive\" else 0, labels)))"],"metadata":{"id":"ASxsVgHManES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_sentences, test_sentences, train_labels, test_labels = train_test_split(review, labels, test_size=0.2)"],"metadata":{"id":"OzuoPWhkbLI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 1000\n","max_length = 120\n","embedding_dim = 16\n","trunc_type = 'post'\n","oov_tok = \"<OOV>\""],"metadata":{"id":"7K5LM2ljco8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Initialize the tokenizer class\n","tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n","\n","# Generate the word index dictionary for training sentences\n","tokenizer.fit_on_texts(train_sentences)\n","word_index = tokenizer.word_index\n","\n","# Generate and pad the training sequences\n","sequences = tokenizer.texts_to_sequences(train_sentences)\n","padded = pad_sequences(sequences, maxlen = max_length, truncating= trunc_type)\n","\n","# Generate and pad the test sequences\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","test_padded = pad_sequences(test_sequences, maxlen = max_length, truncating=trunc_type)"],"metadata":{"id":"fmHKU3DudDd1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Construcción del modelo"],"metadata":{"id":"V7hxm_L5r2hs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdMnkoilrEZu"},"outputs":[],"source":["# Build the model\n","model = keras.Sequential([\n","    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    keras.layers.LSTM(64, return_sequences=True),\n","    keras.layers.LSTM(32),\n","    keras.layers.Dense(6, activation = 'relu'),\n","    keras.layers.Dense(1, activation = 'sigmoid')\n","])"]},{"cell_type":"markdown","source":["### 2. Compilación y resumen del modelo"],"metadata":{"id":"dku5-gnMsfxg"}},{"cell_type":"code","source":["# Setup the training parameters\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()"],"metadata":{"id":"hFXey6FSsjaY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Entremaniento del modelo"],"metadata":{"id":"cS0TsDS1s2Nr"}},{"cell_type":"code","source":["num_epochs = 10\n","\n","# Train the model\n","history = model.fit(padded,\n","                    train_labels,\n","                    epochs=num_epochs,\n","                    validation_data=(test_padded, test_labels))"],"metadata":{"id":"GCHKpBN-s5DX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Visualización del historial de entrenamiento"],"metadata":{"id":"DdJeF8Z6tJnR"}},{"cell_type":"code","source":["pd.DataFrame(history.history).plot(grid=True)"],"metadata":{"id":"pHwwRLPHtNvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preguntas\n","1. ¿Qué tipo de modelo de red neuronal se construye en el código?\n","2. ¿Cuál es la función de activación utilizada en la capa de salida y por qué se elige esta función para\n","este problema?\n","3. ¿Cuál es la diferencia entre una capa LSTM bidireccional y una capa LSTM unidireccional?\n","4. ¿Qué signican los parámetros return_sequences=True en la primera capa LSTM bidireccional?\n","5. ¿Qué función de pérdida se utiliza en el modelo y por qué es adecuada para problemas de\n","clasicación binaria?\n","6. ¿Qué métrica se utiliza para evaluar el rendimiento del modelo durante el entrenamiento?\n","7. ¿Por qué se utilizan dos capas LSTM bidireccionales en el modelo?\n","8. ¿Qué hace la capa de embedding en el modelo y por qué es necesaria?\n"],"metadata":{"id":"B3pNAE9ltWnv"}},{"cell_type":"markdown","source":["### Ejercicios\n","1. Modica el número de unidades de memoria en las capas LSTM y observa cómo afecta el\n","rendimiento del modelo.\n","2. Cambia la función de activación de la capa densa a 'tanh' y compara los resultados.\n","3. Entrena el modelo durante más épocas y observa si mejora el rendimiento en el conjunto de\n","validación.\n","4. Experimenta con diferentes valores para los parámetros max_length y vocab_size y observa cómo\n","afectan el tamaño y la eciencia del modelo.\n","5. Agrega una capa de regularización, como Dropout, al modelo y observa si mejora la generalización\n","del modelo.\n","6. Cambia la arquitectura del modelo agregando más capas ocultas y observa cómo afecta la\n","capacidad de aprendizaje del modelo\n","\n"],"metadata":{"id":"2Q6KUgbPtcWB"}}]}